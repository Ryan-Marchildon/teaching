{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Conv2D Transform from Scratch in Numpy\n",
    "***\n",
    "\n",
    "This notebook details how to construct a conv2D transform from scratch, which is the foundation of the convolutional layers used in modern computer vision techniques based on deep learning with neural networks. \n",
    "\n",
    "Also covered are kernel transforms for:\n",
    "* Dilated Convolutions\n",
    "* Custom Sampling Grids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimized Multi-Input, Multi-Channel 2D Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsample_images(images, n_x, n_y, filters_shape, stride):\n",
    "    '''\n",
    "    Extracts image subsamples corresponding to the sub-arrays that would\n",
    "    be element-wise multiplied with a set of kernels in a 2D convolution. \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    images : numpy array\n",
    "        Array of 2D images to be subsampled, of dimension\n",
    "        (batch_size, width, height, num_channels). \n",
    "    \n",
    "    n_x : int\n",
    "        Number of sampling steps along the x-dimension.\n",
    "    \n",
    "    n_y : int\n",
    "        Number of sampling steps along the y-dimension.\n",
    "    \n",
    "    filters_shape : tuple\n",
    "        Shape of the filter array being convolved with the 2D image, \n",
    "        given as (num_filters, kernel_width, kernel_height, num_channels).\n",
    "    \n",
    "    stride : tuple\n",
    "        Stride of the sampling steps along the x and y dimensions, \n",
    "        given as (stride_x, stride_y).\n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    subsamples : numpy array\n",
    "        Array containing the image subsamples having dimension\n",
    "        (batch_size, kernel_width * kernel_height * num_channels). \n",
    "        Note that the subsamples have been reshaped to 1D vectors and\n",
    "        concatenated across channels, so that they can be efficiently\n",
    "        convolved with the filters using a dot product. \n",
    "        \n",
    "    '''\n",
    "    \n",
    "    (_, k_width, k_height, num_channels) = filters_shape \n",
    "    batch_size = images.shape[0]\n",
    "    \n",
    "    subsamples = np.zeros((n_x * n_y, batch_size, k_width * k_height * num_channels))\n",
    "    ids = 0\n",
    "    for dx in range(n_x): \n",
    "        for dy in range(n_y):\n",
    "            x = stride[0] * dx\n",
    "            y = stride[1] * dy\n",
    "            sample = images[:, x:(x + k_width), y:(y + k_height), :]\n",
    "            sample = sample.reshape((batch_size, k_width * k_height * num_channels), order='C')\n",
    "            subsamples[ids, :, :] = sample\n",
    "            ids += 1\n",
    "                 \n",
    "    return subsamples\n",
    "\n",
    "    \n",
    "def conv2d_transform(inputs, filters, stride=(1, 1), padding='valid'):\n",
    "    '''\n",
    "    Applies a 2-dimensional convolution of user-provided filters and inputs \n",
    "    using the specified stride and padding. \n",
    "    \n",
    "    To optimize computational efficiency, the following approach has been taken:\n",
    "    *  Compute image subsamples corresponding to the sub-arrays multiplied by the\n",
    "        convolutional kernel for each stranslation step. \n",
    "    * Unravel the x and y image subsample dimensions into a single vector and \n",
    "        concatenate vectors across the channels. Vectorize all convolutional filters\n",
    "        using the same procedure. \n",
    "    * Compute the convolution as a dot-product between the above unraveled image\n",
    "        subsample vector and convolutional filters, then reshape the output into\n",
    "        a 2D feature map. \n",
    "    \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    inputs : numpy array\n",
    "        Array containing input images or feature maps \n",
    "        of shape (batch_size, width, height, num_channels). \n",
    "        \n",
    "    filters : numpy array\n",
    "        Array containing convolution filters of shape\n",
    "        (num_filters, kernel_width, kernel_height, num_channels). \n",
    "        \n",
    "    stride : tuple\n",
    "        Specifies the stride (translation step size) of the convolutional\n",
    "        kernel across the input images (feature maps). Usage: (stride_x, stride_y). \n",
    "        Stride must be specified as an integer greater than 0. \n",
    "    \n",
    "    padding : string\n",
    "        Desired padding type, 'valid' or 'same'; 'valid' padding does not pad the inputs\n",
    "        with zeros and hence the output layer will be a smaller size; 'same' padding\n",
    "        add zero padding of width 1 around the edge of the input arrays to preserve\n",
    "        size when convolved with a kernel using a stride of 1. \n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    outputs : numpy array\n",
    "        Array containing the output feature maps of the convolution layer, having shape\n",
    "        (batch_size, x_pixels, y_pixels)\n",
    "        \n",
    "    \n",
    "    Written by Ryan P. Marchildon, April 2020\n",
    "    \n",
    "    '''\n",
    "    batch_size, width, height, num_channels = inputs.shape\n",
    "    num_filters, k_width, k_height, k_channels = filters.shape\n",
    "    (stride_x, stride_y) = stride\n",
    "    \n",
    "    # check assumptions on input parameters\n",
    "    assert padding == 'valid' or 'same', \"Padding must be equal to 'valid' or 'same'.\"\n",
    "    assert type(stride) == tuple, \"Stride must be specified as a tuple of form (stride_x, stride_y).\"\n",
    "    assert type(stride_x) or type(stride_y) == int, \"Stride must be specified as a tuple of integers.\"\n",
    "    assert stride[0] and stride[1] > 0, 'Stride cannot be less than 1 along any dimension.'\n",
    "    assert len(inputs.shape) == 4, \"Input must be an array of shape (batch_size, width, height, num_channels).\"\n",
    "    assert len(filters.shape) == 4, \"Filters must be an array of shape (num_filters, width, height, num_channels).\"\n",
    "        \n",
    "    # pad the input arrays with zeros\n",
    "    if padding == 'same':\n",
    "        inputs = np.pad(inputs, ((0, 0), (1, 1), (1, 1), (0, 0)), 'constant', constant_values=0)\n",
    "        batch_size, width, height, num_channels = inputs.shape # update input dimensions\n",
    "\n",
    "    # compute the expected dimensions of the output feature map, which equals the\n",
    "    # number of kernel steps (translations) across the image\n",
    "    n_x = int((width - k_width)/stride_x + 1)\n",
    "    n_y = int((height - k_height)/stride_y + 1)\n",
    "\n",
    "    # obtain the image subsamples\n",
    "    subsamples = subsample_images(inputs, n_x, n_y, filters.shape, stride)\n",
    "            \n",
    "    # reshape the filters to a single vector that is concatenated across channels\n",
    "    filters = filters.reshape((num_filters, k_width * k_height * num_channels), order='C')\n",
    "    \n",
    "    # compute the convolution by taking the dot product with the unravelled kernels \n",
    "    output = np.tensordot(subsamples, filters, axes=(2, 1))\n",
    "\n",
    "    # reshape output to (batch_size, x_pixels, y_pixels, num_feature_maps)\n",
    "    output = output.transpose(1, 0, 2) # re-order the axes\n",
    "    output = output.reshape((batch_size, n_x, n_y, num_filters), order='C')\n",
    "\n",
    "    return output\n",
    "\n",
    "\n",
    "# UNIT TESTS\n",
    "# ----------\n",
    "# multi-channel input (e.g. RBG)\n",
    "x1 = np.array([\n",
    "    [0, 2, 2, 2, 2],\n",
    "    [0, 2, 1, 2, 1],\n",
    "    [2, 1, 2, 2, 2],\n",
    "    [2, 2, 1, 1, 2],\n",
    "    [1, 2, 2, 0, 2]\n",
    "])\n",
    "\n",
    "x2 = np.array([\n",
    "    [2, 1, 0, 2, 2],\n",
    "    [1, 2, 1, 1, 0],\n",
    "    [2, 2, 0, 0, 2],\n",
    "    [0, 2, 0, 1, 1],\n",
    "    [2, 0, 0, 1, 1]\n",
    "])\n",
    "\n",
    "x3 = np.array([\n",
    "    [1, 2, 0, 0, 2],\n",
    "    [0, 1, 1, 2, 2],\n",
    "    [2, 2, 2, 2, 2],\n",
    "    [2, 1, 2, 2, 2],\n",
    "    [1, 2, 2, 1, 0]\n",
    "])\n",
    "\n",
    "test_input_mc = np.stack([x1, x2, x3], axis=-1)\n",
    "test_input_mc= test_input_mc.reshape(1, *test_input_mc.shape)\n",
    "\n",
    "# multi-channel filter (1 filter contains multiple kernels)\n",
    "k1 = np.array([\n",
    "    [0, 0, -1],\n",
    "    [0, 0, -1],\n",
    "    [1, -1, 0]\n",
    "])\n",
    "\n",
    "k2 = np.array([\n",
    "    [-1, 0, 1],\n",
    "    [-1, 0, 0],\n",
    "    [1, 0, 1]\n",
    "])\n",
    "\n",
    "k3 = np.array([\n",
    "    [-1, 0, -1],\n",
    "    [-1, -1, 1],\n",
    "    [0, 1, 1]\n",
    "])\n",
    "\n",
    "test_filter_mc = np.stack((k1, k2, k3), axis=-1)\n",
    "test_filter_mc= test_filter_mc.reshape(1, *test_filter_mc.shape)\n",
    "\n",
    "# output feature maps (only 1 since there is only 1 filter applied to 1 image)\n",
    "test_output_mc = np.array([\n",
    "    [2, 2, 0],\n",
    "    [1, -4, -5],\n",
    "    [-2, -8, -5]\n",
    "])\n",
    "test_output_mc = test_output_mc.reshape(1, *test_output_mc.shape, 1)\n",
    "\n",
    "print('Test Passed?', \n",
    "      np.array_equal(\n",
    "          test_output_mc, \n",
    "          conv2d_transform(\n",
    "              test_input_mc, \n",
    "              test_filter_mc, \n",
    "              padding='same', \n",
    "              stride=(2, 2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dilated Convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dilate(kernel, d=0):\n",
    "    '''\n",
    "    Applies a dilation to an input convolution kernel. \n",
    "    \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    d : int \n",
    "        The dilation factor (zero returns a conventional convolution).\n",
    "        \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    output : numpy array  \n",
    "        The dilated kernel.\n",
    "    \n",
    "    '''\n",
    "    assert type(kernel) == np.ndarray, \"Input kernel must be an numpy array.\"\n",
    "    assert type(d) == int, \"Dilation factor 'd' must be a non-negative integer.\"\n",
    "    assert d >= 0, \"Dilation factor 'd' must be a non-negative integer.\"\n",
    "    \n",
    "    if d == 0:\n",
    "        return kernel\n",
    "    else: \n",
    "        # how many zeros are we injecting\n",
    "        num_zeros_x = (kernel.shape[0] - 1)*d\n",
    "        num_zeros_y = (kernel.shape[1] - 1)*d\n",
    "        \n",
    "        # initialize dilated array\n",
    "        output = np.zeros((kernel.shape[0] + num_zeros_x, kernel.shape[1] + num_zeros_y))\n",
    "        \n",
    "        # populate the non-zero entries\n",
    "        for dx in range(kernel.shape[0]):\n",
    "            for dy in range(kernel.shape[1]):\n",
    "                output[(d + 1)*dx, (d + 1)* dy] = kernel[dx, dy]\n",
    "                \n",
    "        return output\n",
    "    \n",
    "    \n",
    "# UNIT TESTS\n",
    "# ----------\n",
    "test_kernel = np.array([\n",
    "    [1, 0, 1],\n",
    "    [0, 1, 1],\n",
    "    [1, 0, 1]\n",
    "])\n",
    "\n",
    "test_dilation_output = np.array([\n",
    "    [1, 0, 0, 0, 1], \n",
    "    [0, 0, 0, 0, 0], \n",
    "    [0, 0, 1, 0, 1], \n",
    "    [0, 0, 0, 0, 0],\n",
    "    [1, 0, 0, 0, 1]\n",
    "])\n",
    "\n",
    "print('Test Passed?', np.array_equal(test_dilation_output, dilate(test_kernel, 1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kernel with a Custom Sampling Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_kernel(weights, sampling_grid):\n",
    "    '''\n",
    "    Defines a new convolution kernel where the weights are\n",
    "    redistributed with an offset defined by sampling_grid \n",
    "    relative to their original coordinates. \n",
    "    \n",
    "    Example Usage:\n",
    "\n",
    "        A 3x3 weights array of:\n",
    "            1 1 1\n",
    "            1 1 1\n",
    "            1 1 1\n",
    "\n",
    "        and 3x3x2 sampling_grid of:\n",
    "            [-1, -2] [-1, 0] [-1, 2]\n",
    "            [0, -1] [0, 0] [0, 1]\n",
    "            [1, -2] [1, 0] [1, 2]\n",
    "\n",
    "        would return the following transformed kernel:\n",
    "            1 0 0 1 0 0 1\n",
    "            0 0 0 0 0 0 0\n",
    "            0 1 0 1 0 1 0\n",
    "            0 0 0 0 0 0 0\n",
    "            1 0 0 1 0 0 1\n",
    "            \n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    weights : numpy array\n",
    "    \n",
    "        An array containing the convolutional filter weights of dimension\n",
    "        (kernel_x_size, kernel_y_size, num_channels). \n",
    "    \n",
    "    sampling_grid : numpy array\n",
    "        An array containing sampling offset coordinates for each of the \n",
    "        convolutional filter weights. Of dimension (kernel_x_size, kernel_y_size, 2),\n",
    "        where along the third axis, the offsets are specified as [x_offset, y_offset]. \n",
    "        Note that offsets are relative to the coordinate of the original kernel element. \n",
    "    \n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    transformed_kernel : numpy array\n",
    "    \n",
    "\n",
    "    '''\n",
    "    weights_span_x, weights_span_y, num_channels = weights.shape\n",
    "    \n",
    "    # transform the coordinates of the sampling grid to be \n",
    "    # relative to the [0, 0] element of the original kernel\n",
    "    for x in range(sampling_grid.shape[0]):\n",
    "        for y in range(sampling_grid.shape[1]):\n",
    "            sampling_grid[x, y, 0] += x \n",
    "            sampling_grid[x, y, 1] += y\n",
    "\n",
    "    # translate the coordinate system to put the origin\n",
    "    # at the top-most left sampling coordinate\n",
    "    x_min = np.min(sampling_grid[:, :, 0])\n",
    "    y_min = np.min(sampling_grid[:, :, 1])\n",
    "    sampling_grid[:, :, 0] -= x_min\n",
    "    sampling_grid[:, :, 1] -= y_min\n",
    "\n",
    "    # create a sparse array of the minimum size needed\n",
    "    # to represent the transformed kernel and populate\n",
    "    # it with the kernel weights at the sample grid coordinates\n",
    "    x_max = np.max(sampling_grid[:, :, 0])\n",
    "    y_max = np.max(sampling_grid[:, :, 1])\n",
    "    transformed_kernel = np.zeros((x_max + 1, y_max + 1, num_channels))\n",
    "    for x in range(weights.shape[0]):\n",
    "        for y in range(weights.shape[1]):\n",
    "            x_sample = sampling_grid[x, y, 0]\n",
    "            y_sample = sampling_grid[x, y, 1]\n",
    "            transformed_kernel[x_sample, y_sample, :] = weights[x, y, :]\n",
    "    \n",
    "    \n",
    "    return transformed_kernel\n",
    "\n",
    "\n",
    "# UNIT TESTS\n",
    "# ----------\n",
    "test_weights = np.ones((3, 3, 3))\n",
    "\n",
    "test_sampling_grid = np.array([\n",
    "    [[-1, -2], [-1, 0], [-1, 2]], \n",
    "    [[0, -1], [0, 0], [0, 1]], \n",
    "    [[1, -2], [1, 0], [1, 2]]\n",
    "])\n",
    "\n",
    "output_sub_array = np.array([\n",
    "    [1, 0, 0, 1, 0, 0, 1], \n",
    "    [0, 0, 0, 0, 0, 0, 0], \n",
    "    [0, 1 ,0, 1, 0, 1, 0], \n",
    "    [0, 0, 0, 0, 0, 0, 0], \n",
    "    [1, 0, 0, 1, 0, 0, 1]\n",
    "])\n",
    "\n",
    "test_output = np.repeat(output_sub_array[:, :, np.newaxis], 3, axis=2)\n",
    "\n",
    "print('Test Passed?', np.array_equal(test_output, transform_kernel(test_weights, test_sampling_grid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note: Convolving with a 9x9 Input to Obtain a 7x7 Output\n",
    "\n",
    "Assuming the image size is larger than the size of the transformed kernel, the dimensions of the output would be:\n",
    "* `n_x = (image_width - transformed_kernel_width + 1)`\n",
    "* `n_y = (image_height - transformed_kernel_height + 1)`\n",
    "\n",
    "To achieve the desired output size, we would need to pad the input image with:\n",
    "* `pad_x = (7 - n_x)`, zeros along x\n",
    "* `pad_y = (7 - n_y)`, zeros along y\n",
    "\n",
    "If the image is smaller than the kernel, the above equations still give us the correct number of zeros to pad. For example, if along x, the kernel has size 11 and the image size 9, then n_x = -1, and pad_x = 8. This will reshape the input to be (8 + 9) = 17 across which, when convolved with the size 11 filter, gives us an output dimension of (17 - 11 + 1) = 7.\n",
    "\n",
    "Note that padding would be asymmetric in the case that pad_x or pad_y are odd integers.\n",
    "Assymetric padding can be achieved using the code shown below. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "pad_x = 2\n",
    "pad_y = 3\n",
    "\n",
    "print('Before:')\n",
    "print(test_input_mc[0, :, :, 0])\n",
    "\n",
    "print('\\nAfter:')\n",
    "padding = ((0, 0), (math.floor(pad_x/2), math.ceil(pad_x/2)), (math.floor(pad_y/2), math.ceil(pad_y/2)), (0, 0))\n",
    "temp = np.pad(test_input_mc, padding, 'constant', constant_values=0)\n",
    "print(temp[0, :, :, 0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ml-general]",
   "language": "python",
   "name": "conda-env-ml-general-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
